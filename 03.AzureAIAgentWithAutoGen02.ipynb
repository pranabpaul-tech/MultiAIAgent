{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install \"autogen-ext[openai]\"\n",
    "! pip install autogen-agentchat\n",
    "! pip install azure-ai-projects \n",
    "! pip install azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import BingGroundingTool,CodeInterpreterTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=\"gpt-4\",\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    model = \"gpt-4\",\n",
    "    azure_endpoint=\"our Azure OpenAI Service endpoint from Azure AI Foundry\",\n",
    "    # azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    api_key=\"Your API Key from Azure AI Foundry\", # For key-based authentication.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    conn_str='Your Project connection string from Azure Foundry here',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bing_connection = project_client.connections.get(\n",
    "    connection_name='Grounding with Bing Search connection name from Azure Foundry here'\n",
    ")\n",
    "\n",
    "conn_id = bing_connection.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def web_ai_agent(query: str) -> str:\n",
    "    print(\"This is Bing for Azure AI Agent Service .......\")\n",
    "    bing = BingGroundingTool(connection_id=conn_id)\n",
    "    with project_client:\n",
    "        agent = project_client.agents.create_agent(\n",
    "            model=\"gpt-4\",\n",
    "            name=\"my-assistant\",\n",
    "            instructions=\"\"\"        \n",
    "                You are a web search agent.\n",
    "                Your only tool is search_tool - use it to find information.\n",
    "                You make only one search call at a time.\n",
    "                Once you have the results, you never do calculations based on them.\n",
    "            \"\"\",\n",
    "            tools=bing.definitions,\n",
    "            headers={\"x-ms-enable-preview\": \"true\"}\n",
    "        )\n",
    "        print(f\"Created agent, ID: {agent.id}\")\n",
    "\n",
    "        # Create thread for communication\n",
    "        thread = project_client.agents.create_thread()\n",
    "        print(f\"Created thread, ID: {thread.id}\")\n",
    "\n",
    "        # Create message to thread\n",
    "        message = project_client.agents.create_message(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=query,\n",
    "        )\n",
    "        print(f\"SMS: {message}\")\n",
    "        # Create and process agent run in thread with tools\n",
    "        run = project_client.agents.create_and_process_run(thread_id=thread.id, agent_id=agent.id)\n",
    "        print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "        if run.status == \"failed\":\n",
    "            print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "        # Delete the assistant when done\n",
    "        # project_client.agents.delete_agent(agent.id)\n",
    "        # print(\"Deleted agent\")\n",
    "\n",
    "        # Fetch and log all messages\n",
    "        messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "        # print(\"Messages:\"+ messages[\"data\"][0][\"content\"][0][\"text\"][\"value\"])\n",
    "    return messages[\"data\"][0][\"content\"][0][\"text\"][\"value\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def save_blog_agent(blog_content: str) -> str:\n",
    "\n",
    "    print(\"This is Code Interpreter for Azure AI Agent Service .......\")\n",
    "    print(blog_content)\n",
    "    with project_client:\n",
    "\n",
    "        code_interpreter = CodeInterpreterTool()\n",
    "        \n",
    "        agent = project_client.agents.create_agent(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            name=\"my-agent\",\n",
    "            instructions=\"You are helpful agent\",\n",
    "            tools=code_interpreter.definitions,\n",
    "            # tool_resources=code_interpreter.resources,\n",
    "        )\n",
    "        \n",
    "        thread = project_client.agents.create_thread()\n",
    "\n",
    "        message = project_client.agents.create_message(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=\"\"\"\n",
    "                    You are my Python programming assistant. Generate code and execute it according to the following requirements\n",
    "\n",
    "                    1. Save \"\"\" + blog_content + \"\"\" to blog-{YYMMDDHHMMSS}.md\n",
    "\n",
    "                    2. give me the download this file link\n",
    "                \"\"\",\n",
    "    \n",
    "        )\n",
    "        # create and execute a run\n",
    "        run = project_client.agents.create_and_process_run(thread_id=thread.id, agent_id=agent.id)\n",
    "        print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "        if run.status == \"failed\":\n",
    "            # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "            print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "        # # delete the original file from the agent to free up space (note: this does not delete your version of the file)\n",
    "        # project_client.agents.delete_file(file.id)\n",
    "        # print(\"Deleted file\")\n",
    "\n",
    "        # print the messages from the agent\n",
    "        messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "        # print(f\"Messages: {messages}\")\n",
    "\n",
    "        # get the most recent message from the assistant\n",
    "        # last_msg = messages[\"data\"][0][\"content\"][0][\"text\"][\"value\"]\n",
    "        # if last_msg:\n",
    "        #   print(f\"Last Message: {last_msg}\")\n",
    "\n",
    "        # print(f\"File: {messages.file_path_annotations}\")\n",
    "\n",
    "\n",
    "        for file_path_annotation in messages.file_path_annotations:\n",
    "\n",
    "            file_name = os.path.basename(file_path_annotation.text)\n",
    "\n",
    "            project_client.agents.save_file(file_id=file_path_annotation.file_path.file_id, file_name=file_name,target_dir=\"./blog\")\n",
    "            \n",
    "\n",
    "        #project_client.agents.delete_agent(agent.id)\n",
    "        #print(\"Deleted agent\")\n",
    "        return \"Saved\"\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bing_search_agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=az_model_client,\n",
    "    tools=[web_ai_agent],\n",
    "    system_message=\"Use tools to solve tasks.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_blog_content_agent = AssistantAgent(\n",
    "    name=\"save_blog_content_agent\",\n",
    "    model_client=az_model_client,\n",
    "    tools=[save_blog_agent],\n",
    "    system_message=\"\"\"\n",
    "        Save blog content. Respond with 'Saved' to when your blog are saved.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_agent = AssistantAgent(\n",
    "    name=\"write_agent\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"\"\"\n",
    "        You are a blog writer, please help me write a blog based on bing search content.\"\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_termination = TextMentionTermination(\"Saved\")\n",
    "# Define a termination condition that stops the task after 5 messages.\n",
    "max_message_termination = MaxMessageTermination(10)\n",
    "# Combine the termination conditions using the `|`` operator so that the\n",
    "# task stops when either condition is met.\n",
    "termination = text_termination | max_message_termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reflection_team = RoundRobinGroupChat([write_agent, save_blog_content_agent], termination_condition=termination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await Console(\n",
    "                reflection_team.run_stream(task=\"\"\"\n",
    "\n",
    "                   I am writing a blog about machine learning. Search for the following 3 questions and write a  blog based on the search results ,save it\n",
    "                    \n",
    "                    1. What is Machine Learning?\n",
    "                    2. The difference between AI and ML\n",
    "                    3. The history of Machine Learning\n",
    "\n",
    "                               \n",
    "\n",
    "    \"\"\")\n",
    ")  # Stream the messages to the console."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
